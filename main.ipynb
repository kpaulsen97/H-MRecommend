{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4179a36",
   "metadata": {},
   "source": [
    "# Implicit ALS base model for the competition H&M Personalized Fashion Recommendations.\n",
    "\n",
    "In this notebook we use ALS (Alternating Least Squares), but the library supports a lot of other models with not many changes.\n",
    "\n",
    "ALS is one of the most used ML models for recommender systems. It's a matrix factorization method based on SVD (it's actually an approximated, numerical version of SVD). Basically, ALS factorizes the interaction matrix (user x items) into two smaller matrices, one for item embeddings and one for user embeddings. These new matrices are built in a manner such that the multiplication of a user and an item gives (approximately) it's interaction score. This build embeddings for items and for users that live in the same vector space, allowing the implementation of recommendations as simple cosine distances between users and items. This is, the 12 items we recommend for a given user are the 12 items with their embedding vectors closer to the user embedding vector.\n",
    "\n",
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb5cdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.5.2-cp38-cp38-win_amd64.whl (628 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from implicit) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from implicit) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from implicit) (1.8.0)\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402bc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.evaluation import mean_average_precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd60e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = 'transactions_train.csv'\n",
    "csv_sub = 'sample_submission.csv'\n",
    "csv_users = 'customers.csv'\n",
    "csv_items = 'articles.csv'\n",
    "\n",
    "df = pd.read_csv(csv_train, dtype={'article_id': str}, parse_dates=['t_dat'])\n",
    "df_sub = pd.read_csv(csv_sub)\n",
    "dfu = pd.read_csv(csv_users)\n",
    "dfi = pd.read_csv(csv_items, dtype={'article_id': str})\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac525ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190911, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying with less data:\n",
    "# https://www.kaggle.com/tomooinubushi/folk-of-time-is-our-best-friend/notebook\n",
    "df = df[df['t_dat'] > '2020-08-21']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41fd8180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-22 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For validation this means 3 weeks of training and 1 week for validation\n",
    "# For submission, it means 4 weeks of training\n",
    "df['t_dat'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8282d1",
   "metadata": {},
   "source": [
    "### Assign autoincrementing ids starting from 0 to both users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01eea70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_USERS = dfu['customer_id'].unique().tolist()\n",
    "ALL_ITEMS = dfi['article_id'].unique().tolist()\n",
    "\n",
    "user_ids = dict(list(enumerate(ALL_USERS)))\n",
    "item_ids = dict(list(enumerate(ALL_ITEMS)))\n",
    "\n",
    "user_map = {u: uidx for uidx, u in user_ids.items()}\n",
    "item_map = {i: iidx for iidx, i in item_ids.items()}\n",
    "\n",
    "df['user_id'] = df['customer_id'].map(user_map)\n",
    "df['item_id'] = df['article_id'].map(item_map)\n",
    "\n",
    "del dfu, dfi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccd731",
   "metadata": {},
   "source": [
    "### Create csr matrix (user x item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62017504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1371980x105542 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1190911 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df['user_id'].values\n",
    "col = df['item_id'].values\n",
    "data = np.ones(df.shape[0])\n",
    "coo_train = coo_matrix((data, (row, col)), shape=(len(ALL_USERS), len(ALL_ITEMS)))\n",
    "coo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a00a05",
   "metadata": {},
   "source": [
    "### Check that model works ok with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe18621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\implicit\\utils.py:31: UserWarning: Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488f15eefca040d3adea46d6e0c81a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=10, iterations=2)\n",
    "model.fit(coo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0fc68",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84702b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_user_item_coo(df):\n",
    "    \"\"\" Turn a dataframe with transactions into a COO sparse items x users matrix\"\"\"\n",
    "    row = df['user_id'].values\n",
    "    col = df['item_id'].values\n",
    "    data = np.ones(df.shape[0])\n",
    "    coo = coo_matrix((data, (row, col)), shape=(len(ALL_USERS), len(ALL_ITEMS)))\n",
    "    return coo\n",
    "\n",
    "\n",
    "def split_data(df, validation_days=7):\n",
    "    \"\"\" Split a pandas dataframe into training and validation data, using <<validation_days>>\n",
    "    \"\"\"\n",
    "    validation_cut = df['t_dat'].max() - pd.Timedelta(validation_days)\n",
    "\n",
    "    df_train = df[df['t_dat'] < validation_cut]\n",
    "    df_val = df[df['t_dat'] >= validation_cut]\n",
    "    return df_train, df_val\n",
    "\n",
    "def get_val_matrices(df, validation_days=7):\n",
    "    \"\"\" Split into training and validation and create various matrices\n",
    "        \n",
    "        Returns a dictionary with the following keys:\n",
    "            coo_train: training data in COO sparse format and as (users x items)\n",
    "            csr_train: training data in CSR sparse format and as (users x items)\n",
    "            csr_val:  validation data in CSR sparse format and as (users x items)\n",
    "    \n",
    "    \"\"\"\n",
    "    df_train, df_val = split_data(df, validation_days=validation_days)\n",
    "    coo_train = to_user_item_coo(df_train)\n",
    "    coo_val = to_user_item_coo(df_val)\n",
    "\n",
    "    csr_train = coo_train.tocsr()\n",
    "    csr_val = coo_val.tocsr()\n",
    "    \n",
    "    return {'coo_train': coo_train,\n",
    "            'csr_train': csr_train,\n",
    "            'csr_val': csr_val\n",
    "          }\n",
    "\n",
    "\n",
    "def validate(matrices, factors=200, iterations=20, regularization=0.01, show_progress=True):\n",
    "    \"\"\" Train an ALS model with <<factors>> (embeddings dimension) \n",
    "    for <<iterations>> over matrices and validate with MAP@12\n",
    "    \"\"\"\n",
    "    coo_train, csr_train, csr_val = matrices['coo_train'], matrices['csr_train'], matrices['csr_val']\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42)\n",
    "    model.fit(coo_train, show_progress=show_progress)\n",
    "    \n",
    "    # The MAPK by implicit doesn't allow to calculate allowing repeated items, which is the case.\n",
    "    # TODO: change MAP@12 to a library that allows repeated items in prediction\n",
    "    map12 = mean_average_precision_at_k(model, csr_train, csr_val, K=12, show_progress=show_progress, num_threads=4)\n",
    "    print(f\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} ==> MAP@12: {map12:6.5f}\")\n",
    "    return map12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6625bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = get_val_matrices(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc845a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors:  40 - Iterations:  3 - Regularization: 0.010 ==> MAP@12: 0.00392\n",
      "Best MAP@12 found. Updating: {'factors': 40, 'iterations': 3, 'regularization': 0.01}\n",
      "Factors:  40 - Iterations: 12 - Regularization: 0.010 ==> MAP@12: 0.00533\n",
      "Best MAP@12 found. Updating: {'factors': 40, 'iterations': 12, 'regularization': 0.01}\n",
      "Factors:  40 - Iterations: 14 - Regularization: 0.010 ==> MAP@12: 0.00523\n",
      "Factors:  40 - Iterations: 15 - Regularization: 0.010 ==> MAP@12: 0.00528\n",
      "Factors:  40 - Iterations: 20 - Regularization: 0.010 ==> MAP@12: 0.00532\n",
      "Factors:  50 - Iterations:  3 - Regularization: 0.010 ==> MAP@12: 0.00460\n",
      "Factors:  50 - Iterations: 12 - Regularization: 0.010 ==> MAP@12: 0.00543\n",
      "Best MAP@12 found. Updating: {'factors': 50, 'iterations': 12, 'regularization': 0.01}\n",
      "Factors:  50 - Iterations: 14 - Regularization: 0.010 ==> MAP@12: 0.00536\n",
      "Factors:  50 - Iterations: 15 - Regularization: 0.010 ==> MAP@12: 0.00534\n",
      "Factors:  50 - Iterations: 20 - Regularization: 0.010 ==> MAP@12: 0.00528\n",
      "Factors:  60 - Iterations:  3 - Regularization: 0.010 ==> MAP@12: 0.00454\n",
      "Factors:  60 - Iterations: 12 - Regularization: 0.010 ==> MAP@12: 0.00575\n",
      "Best MAP@12 found. Updating: {'factors': 60, 'iterations': 12, 'regularization': 0.01}\n",
      "Factors:  60 - Iterations: 14 - Regularization: 0.010 ==> MAP@12: 0.00577\n",
      "Best MAP@12 found. Updating: {'factors': 60, 'iterations': 14, 'regularization': 0.01}\n",
      "Factors:  60 - Iterations: 15 - Regularization: 0.010 ==> MAP@12: 0.00576\n",
      "Factors:  60 - Iterations: 20 - Regularization: 0.010 ==> MAP@12: 0.00578\n",
      "Best MAP@12 found. Updating: {'factors': 60, 'iterations': 20, 'regularization': 0.01}\n",
      "Factors: 100 - Iterations:  3 - Regularization: 0.010 ==> MAP@12: 0.00536\n",
      "Factors: 100 - Iterations: 12 - Regularization: 0.010 ==> MAP@12: 0.00620\n",
      "Best MAP@12 found. Updating: {'factors': 100, 'iterations': 12, 'regularization': 0.01}\n",
      "Factors: 100 - Iterations: 14 - Regularization: 0.010 ==> MAP@12: 0.00626\n",
      "Best MAP@12 found. Updating: {'factors': 100, 'iterations': 14, 'regularization': 0.01}\n",
      "Factors: 100 - Iterations: 15 - Regularization: 0.010 ==> MAP@12: 0.00621\n",
      "Factors: 100 - Iterations: 20 - Regularization: 0.010 ==> MAP@12: 0.00621\n",
      "Factors: 200 - Iterations:  3 - Regularization: 0.010 ==> MAP@12: 0.00652\n",
      "Best MAP@12 found. Updating: {'factors': 200, 'iterations': 3, 'regularization': 0.01}\n",
      "Factors: 200 - Iterations: 12 - Regularization: 0.010 ==> MAP@12: 0.00649\n",
      "Factors: 200 - Iterations: 14 - Regularization: 0.010 ==> MAP@12: 0.00644\n",
      "Factors: 200 - Iterations: 15 - Regularization: 0.010 ==> MAP@12: 0.00641\n"
     ]
    }
   ],
   "source": [
    "best_map12 = 0\n",
    "for factors in [40, 50, 60, 100, 200, 500, 1000]:\n",
    "    for iterations in [3, 12, 14, 15, 20]:\n",
    "        for regularization in [0.01]:\n",
    "            map12 = validate(matrices, factors, iterations, regularization, show_progress=False)\n",
    "            if map12 > best_map12:\n",
    "                best_map12 = map12\n",
    "                best_params = {'factors': factors, 'iterations': iterations, 'regularization': regularization}\n",
    "                print(f\"Best MAP@12 found. Updating: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061ba82",
   "metadata": {},
   "source": [
    "### Training over full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_train = to_user_item_coo(df)\n",
    "csr_train = coo_train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(coo_train, factors=200, iterations=15, regularization=0.01, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42)\n",
    "    model.fit(coo_train, show_progress=show_progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(coo_train, **best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b533fa",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model, csr_train, submission_name=\"submissions.csv\"):\n",
    "    preds = []\n",
    "    batch_size = 2000\n",
    "    to_generate = np.arange(len(ALL_USERS))\n",
    "    for startidx in range(0, len(to_generate), batch_size):\n",
    "        batch = to_generate[startidx : startidx + batch_size]\n",
    "        ids, scores = model.recommend(batch, csr_train[batch], N=12, filter_already_liked_items=False)\n",
    "        for i, userid in enumerate(batch):\n",
    "            customer_id = user_ids[userid]\n",
    "            user_items = ids[i]\n",
    "            article_ids = [item_ids[item_id] for item_id in user_items]\n",
    "            preds.append((customer_id, ' '.join(article_ids)))\n",
    "\n",
    "    df_preds = pd.DataFrame(preds, columns=['customer_id', 'prediction'])\n",
    "    df_preds.to_csv(submission_name, index=False)\n",
    "    \n",
    "    display(df_preds.head())\n",
    "    print(df_preds.shape)\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = submit(model, csr_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5b5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
